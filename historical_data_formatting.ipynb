{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd747637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the range of years to process\n",
    "years = [2021, 2022, 2023, 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "166289f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed betting data for 2021:\n",
      "Processed betting data for 2022:\n",
      "Processed betting data for 2023:\n",
      "Processed betting data for 2024:\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    # Load data for the specific year\n",
    "    input_file = f'./Data/{year}/stanford_{year}_lines.csv'\n",
    "    output_file = f'./Data/{year}/stanford_{year}_lines_altered.csv'\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        betting_data = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {input_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Filter only Bovada lines\n",
    "    betting_data = betting_data[betting_data['LineProvider'].str.contains('Bovada', case=False, na=False)]\n",
    "    \n",
    "    # Sort chronologically\n",
    "    betting_data = betting_data.sort_values(by=betting_data.columns[0], ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    betting_data = betting_data[betting_data['Id'] != 401403970]\n",
    "    \n",
    "    # Save the altered data\n",
    "    betting_data.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Display a sample for verification\n",
    "    print(f\"Processed betting data for {year}:\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7035d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed game stats for 2021:\n",
      "Processed game stats for 2022:\n",
      "Processed game stats for 2023:\n",
      "Processed game stats for 2024:\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    # Input and output file paths for the specific year\n",
    "    input_file = f'./Data/{year}/stanford_{year}_gamestats.csv'\n",
    "    output_file = f'./Data/{year}/stanford_{year}_gamestats_altered.csv'\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        game_stats = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {input_file}\")\n",
    "        continue\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        'Season Type', 'Start Date', 'Start Time Tbd', 'Completed',\n",
    "        'Neutral Site', 'Conference Game', 'Attendance', 'Venue Id', 'Venue',\n",
    "        'Home Id', 'Home Conference', 'Home Division', 'Home Line Scores[0]',\n",
    "        'Home Line Scores[1]', 'Home Line Scores[2]', 'Home Line Scores[3]',\n",
    "        'Away Id', 'Away Line Scores[0]', 'Away Line Scores[1]',\n",
    "        'Away Line Scores[2]', 'Away Line Scores[3]', 'Away Conference',\n",
    "        'Away Division', 'Highlights', 'Notes', 'Week'\n",
    "    ]\n",
    "    \n",
    "    game_stats = game_stats.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Exclude Sacramento State game\n",
    "    game_stats = game_stats[~game_stats['Home Team'].str.contains('Sacramento State', na=False)]\n",
    "    game_stats = game_stats[~game_stats['Away Team'].str.contains('Sacramento State', na=False)]\n",
    "    game_stats = game_stats[~game_stats['Home Team'].str.contains('Cal Poly', na=False)]\n",
    "    game_stats = game_stats[~game_stats['Away Team'].str.contains('Cal Poly', na=False)]\n",
    "    game_stats = game_stats[~game_stats['Home Team'].str.contains('Colgate', na=False)]\n",
    "    game_stats = game_stats[~game_stats['Away Team'].str.contains('Colgate', na=False)]\n",
    "    \n",
    "    # Sort chronologically\n",
    "    game_stats = game_stats.sort_values(by=game_stats.columns[0], ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Save the altered data\n",
    "    game_stats.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Display a sample for verification\n",
    "    print(f\"Processed game stats for {year}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "290cf4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed advanced metrics for 2021:\n",
      "Processed advanced metrics for 2022:\n",
      "Processed advanced metrics for 2023:\n",
      "Processed advanced metrics for 2024:\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    # Input and output file paths for the specific year\n",
    "    input_file = f'./Data/{year}/stanford_{year}_advancedmetrics.csv'\n",
    "    output_file = f'./Data/{year}/stanford_{year}_advancedmetrics_altered.csv'\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        adv_metrics = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {input_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Exclude Sacramento State game\n",
    "    adv_metrics = adv_metrics[~adv_metrics['Opponent'].str.contains('Sacramento State', na=False)]\n",
    "    adv_metrics = adv_metrics[~adv_metrics['Opponent'].str.contains('Cal Poly', na=False)]\n",
    "    adv_metrics = adv_metrics[~adv_metrics['Opponent'].str.contains('Colgate', na=False)]\n",
    "    \n",
    "    # Save the altered data\n",
    "    adv_metrics.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Display a sample for verification\n",
    "    print(f\"Processed advanced metrics for {year}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2873d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6eea897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed team stats for 2021:\n",
      "Processed team stats for 2022:\n",
      "Processed team stats for 2023:\n",
      "Processed team stats for 2024:\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    # Input and output file paths for the specific year\n",
    "    input_file = f'./Data/{year}/stanford_{year}_teamstats.csv'\n",
    "    output_file = f'./Data/{year}/stanford_{year}_teamstats_altered.csv'\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        team_stats = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {input_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Filter for Stanford-specific data\n",
    "    team_stats = team_stats[team_stats['School'] == 'Stanford']\n",
    "    \n",
    "    # Initialize a list to collect data by game ID\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each unique game ID\n",
    "    for game_id in team_stats['Game Id'].unique():\n",
    "        # Filter rows for the current game ID\n",
    "        game_data = team_stats[team_stats['Game Id'] == game_id]\n",
    "        \n",
    "        # Create a dictionary to store all stats for this game\n",
    "        row = {'Game Id': game_id, 'School': 'Stanford'}\n",
    "        \n",
    "        # Loop through each row in this subset to add stats to the dictionary\n",
    "        for _, stat_row in game_data.iterrows():\n",
    "            # Use the stat category as the column name and assign the stat value\n",
    "            stat_category = stat_row['Stat Category']\n",
    "            stat_value = stat_row['Stat']\n",
    "            row[stat_category] = stat_value\n",
    "        \n",
    "        # Append the constructed row to our data list\n",
    "        data.append(row)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    team_stats = pd.DataFrame(data)\n",
    "    \n",
    "    # Sort by the first column (assumed to be 'Game Id')\n",
    "    team_stats = team_stats.sort_values(by=team_stats.columns[0], ascending=True)\n",
    "    \n",
    "    # Fill missing values with 0\n",
    "    team_stats = team_stats.fillna(0)\n",
    "    \n",
    "    # Exclude the Sacramento State game (specific Game Id: 401524010)\n",
    "    team_stats = team_stats[team_stats['Game Id'] != 401524010]\n",
    "    team_stats = team_stats[team_stats['Game Id'] != 401635539]\n",
    "    team_stats = team_stats[team_stats['Game Id'] != 401403970]\n",
    "    \n",
    "    # Sort chronologically\n",
    "    team_stats = team_stats.sort_values(by=team_stats.columns[0], ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # Save the altered data\n",
    "    team_stats.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Display a sample for verification\n",
    "    print(f\"Processed team stats for {year}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f9f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7be6fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved concatenated data for 2021\n",
      "Successfully processed and saved concatenated data for 2022\n",
      "Successfully processed and saved concatenated data for 2023\n",
      "Successfully processed and saved concatenated data for 2024\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    try:\n",
    "        # File paths for the specific year\n",
    "        metrics_file = f'./Data/{year}/stanford_{year}_advancedmetrics_altered.csv'\n",
    "        gamestats_file = f'./Data/{year}/stanford_{year}_gamestats_altered.csv'\n",
    "        lines_file = f'./Data/{year}/stanford_{year}_lines_altered.csv'\n",
    "        teamstats_file = f'./Data/{year}/stanford_{year}_teamstats_altered.csv'\n",
    "        output_file = f'./Data/{year}/concat_stanford_{year}.csv'\n",
    "        \n",
    "        # Load the data\n",
    "        metrics_df = pd.read_csv(metrics_file)\n",
    "        gamestats_df = pd.read_csv(gamestats_file)\n",
    "        lines_df = pd.read_csv(lines_file)\n",
    "        teamstats_df = pd.read_csv(teamstats_file)\n",
    "        \n",
    "        # Combine relevant data into a single DataFrame, aligned by week\n",
    "        data_df = pd.concat([metrics_df, gamestats_df, lines_df, teamstats_df], axis=1)\n",
    "        \n",
    "        # Sort by the 'Week' column in ascending order\n",
    "        if 'Week' in data_df.columns:\n",
    "            data_df = data_df.sort_values(by='Week', ascending=True)\n",
    "            \n",
    "        # Define a function to calculate the outcome\n",
    "        def calculate_outcome(row):\n",
    "            if row['Home Team'] == 'Stanford':\n",
    "                return 1 if row['Home Points'] > row['Away Points'] else -1\n",
    "            elif row['Away Team'] == 'Stanford':\n",
    "                return 1 if row['Away Points'] > row['Home Points'] else -1\n",
    "\n",
    "\n",
    "        # Apply the function to the dataset\n",
    "        data_df['Outcome'] = data_df.apply(calculate_outcome, axis=1)\n",
    "        \n",
    "        # Save concatenated data\n",
    "        data_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Print success message\n",
    "        print(f\"Successfully processed and saved concatenated data for {year}\")\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File missing for year {year}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing data for year {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61730b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for 2021\n",
      "Successfully loaded data for 2022\n",
      "Successfully loaded data for 2023\n",
      "Successfully combined and saved data for 2021-2023\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "\n",
    "# Define the years to concatenate\n",
    "years = [2021, 2022, 2023]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "#Concatenate all historical data for training\n",
    "for year in years:\n",
    "    try:\n",
    "        # File path for the concatenated file of each year\n",
    "        input_file = f'./Data/{year}/concat_stanford_{year}.csv'\n",
    "        \n",
    "        # Load the year's data\n",
    "        year_df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Add a 'Year' column for easier identification in the combined dataset\n",
    "        year_df['Year'] = year\n",
    "        \n",
    "        # Append to the list of DataFrames\n",
    "        dataframes.append(year_df)\n",
    "        \n",
    "        print(f\"Successfully loaded data for {year}\")\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File missing for year {year}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading data for year {year}: {e}\")\n",
    "\n",
    "# Combine all the DataFrames\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Sort by Year and Week\n",
    "    if 'Week' in combined_df.columns:\n",
    "        combined_df = combined_df.sort_values(by=['Year', 'Week'], ascending=[True, True])\n",
    "    \n",
    "    # Save the combined dataset to a new CSV file\n",
    "    combined_df.to_csv('./Data/training_data.csv', index=False)\n",
    "    \n",
    "    print(\"Successfully combined and saved data for 2021-2023\")\n",
    "else:\n",
    "    print(\"No data was combined due to missing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92b55977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outcome to training data\n",
    "data = pd.read_csv('./Data/training_data.csv')\n",
    "\n",
    "# Define a function to calculate the outcome\n",
    "def calculate_outcome(row):\n",
    "    if row['Home Team'] == 'Stanford':\n",
    "        return 1 if row['Home Points'] > row['Away Points'] else -1\n",
    "    elif row['Away Team'] == 'Stanford':\n",
    "        return 1 if row['Away Points'] > row['Home Points'] else -1\n",
    "\n",
    "\n",
    "# Apply the function to the dataset\n",
    "data['Outcome'] = data.apply(calculate_outcome, axis=1)\n",
    "\n",
    "# Save the updated data for further processing\n",
    "data.to_csv('./Data/training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25252671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
